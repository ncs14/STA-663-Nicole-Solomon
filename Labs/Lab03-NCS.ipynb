{
 "metadata": {
  "name": "",
  "signature": "sha256:98ea5157a206e8e0ff3e9d47ad5c2f2aa27ad7c7f3180bcb80b923060cadebe3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "plt.style.use('ggplot')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 1 (10 pts)**. Avoiding catastrophic cancellation.\n",
      "\n",
      "The tail of the standard logistic distributon is given by $1 - F(t) = 1 - (1+e^{-t})^{-1}$.\n",
      "\n",
      "- Define a function `f1` to calculate the tail probability of the logistic distribution using the formula given above\n",
      "- Use `sympy` to find the exact value of the tail distribution (using the same symbolic formula) to 20 decimal digits\n",
      "- Calculate the *relative error* of `f1` when $t = 25$ (The relative error is given by `abs(exact - approximate)/exact`)\n",
      "- Rewrite the expression for the tail of the logistic distribution using simple algebra so that there is no risk of cancellation, and write a function `f2` using this formula. Calculate the *relative error* of `f2` when $t = 25$. \n",
      "- How much more accurate is `f2` compared with `f1` in terms of the relative error?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### 1. Function to calculate tail prob of logistic distn\n",
      "\"\"\" Calculate upper tail Pr of logistic distn \"\"\"\n",
      "def f1(t):\n",
      "    return 1 - pow(1 + np.exp(-t),-1)\n",
      "\n",
      "x = 25\n",
      "y = f1(x)\n",
      "print \"Approximate upper tail prob at t=25: \", y\n",
      "\n",
      "\n",
      "##### 2. Exact value of tail distn using sympy\n",
      "import sympy as sp\n",
      "y_exact = sp.Float(1 - pow(1+np.exp(-x),-1),20)\n",
      "print \"Exact value of upper tail prob: \", y_exact\n",
      "\n",
      "\n",
      "##### 3. Relative error of f1 ----------------------------------\n",
      "relerr = abs(y_exact - y)/y_exact\n",
      "print \"Relative error of f1: \", relerr\n",
      "\n",
      "\n",
      "##### 4. Function that eliminates risk of cancellation\n",
      "def f2(t):\n",
      "    return pow(1+np.exp(t),-1)\n",
      "y2 = f2(x)\n",
      "print \"Approximate upper tail at f2(t=25): \", y2\n",
      "print \"Relative error of f2: \", abs(y_exact - y2)/y_exact\n",
      "y_exact2 = sp.Float(pow(1+np.exp(x),-1))\n",
      "print \"exact2: \", y_exact2\n",
      "print \"Relative error of f2: \", abs(y_exact2 - y2)/y_exact2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Approximate upper tail prob at t=25:  1.38880018596e-11\n",
        "Exact value of upper tail prob:  1.3888001859641008195e-11\n",
        "Relative error of f1:  0\n",
        "Approximate upper tail at f2(t=25):  1.38879438648e-11\n",
        "Relative error of f2:  4.1758973285209657232e-6\n",
        "exact2:  1.38879438647711e-11\n",
        "Relative error of f2:  0\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 2 (10 pts)**. Ill-conditioned linear problems.\n",
      "\n",
      "You are given a $n \\times p$ design matrix $X$ and a $n$-vector of observations $y$ and asked to find the coefficients $\\beta$ that solve the linear equations $X \\beta = y$. \n",
      "```python\n",
      "X = np.load('x.npy')\n",
      "y = np.load('y.npy')\n",
      "```\n",
      "\n",
      "The solution $\\beta$ can also be loaded as\n",
      "```python\n",
      "beta = np.load('b.npy')\n",
      "```\n",
      "\n",
      "- Write a formula that could solve the system of linear equations in terms of $X$ and $y$. Write a function `f1` that takes arguments $X$ and $y$ and returns $\\beta$ using this formula.\n",
      "- How could you code this formula using `np.linalg.solve` that does not require inverting a matrix? Write a function `f2` that takes arguments $X$ and $y$ and returns $\\beta$ using this.\n",
      "- Note that carefully designed algorithms *can* solve this ill-conditioned problem, which is why you should always use library functions for linear algebra rather than write your own.\n",
      "```python\n",
      "np.linalg.lstsq(x, y)[0]\n",
      "```\n",
      "- What happens if you try to solve for $\\beta$ using `f1` or `f2`? Remove the column of $X$ that is making the matrix singular and find the $p-1$ vector $b$ using `f2`.\n",
      "- Note that the solution differs from that given by `np.linalg.lstsq`? This arises because the relevant condition number for `f2` is actually for the matrix $X^TX$ while the condition number of `lstsq` is for the matrix $X$. Why is the condition so high even after removing the column that makes the matrix singular?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.load('x.npy')\n",
      "y = np.load('y.npy')\n",
      "\n",
      "beta = np.load('b.npy')\n",
      "\n",
      "import scipy.linalg as la\n",
      "\n",
      "def f1(xm,ym):\n",
      "    hat_trunc = np.dot(la.inv(np.dot(xm.T,xm)),xm.T)\n",
      "    beta = np.dot(hat_trunc,ym)\n",
      "    return beta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(1111)\n",
      "n, p = 100, 5\n",
      "X = np.random.random(n*p).reshape(n,p)\n",
      "y = np.random.random(n).reshape(n,1)\n",
      "\n",
      "\n",
      "def f1(xm,ym):\n",
      "    import scipy.linalg as la\n",
      "    # H_trunc = (X^T X)^-1 * X^T instead of X*(X^TX)^-1 X^T\n",
      "    hat_trunc = np.dot(la.inv(np.dot(xm.T,xm)),xm.T)\n",
      "    # Beta = H_trunc * Y\n",
      "    beta = np.dot(hat_trunc,ym)\n",
      "    return beta\n",
      "\n",
      "print f1(X,y)\n",
      "\n",
      "\n",
      "def f2(xm,ym):\n",
      "    # need square, invertible matrix on RHS so multiply both sides by X^T\n",
      "    beta = np.linalg.solve(np.dot(xm.T,xm),np.dot(xm.T,ym))\n",
      "    return beta\n",
      "\n",
      "print f2(X,y)\n",
      "\n",
      "\n",
      "print np.linalg.lstsq(X,y)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.16491849]\n",
        " [ 0.14711043]\n",
        " [ 0.32844278]\n",
        " [ 0.09418085]\n",
        " [ 0.29915896]]\n",
        "[[ 0.16491849]\n",
        " [ 0.14711043]\n",
        " [ 0.32844278]\n",
        " [ 0.09418085]\n",
        " [ 0.29915896]]\n",
        "[[ 0.16491849]\n",
        " [ 0.14711043]\n",
        " [ 0.32844278]\n",
        " [ 0.09418085]\n",
        " [ 0.29915896]]\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 3 (10 pts)**. Importance of using efficient algorihtms.\n",
      "\n",
      "- Implement bubble sort\n",
      "- Calculate its big $\\mathcal{O}$ algorithmic complexity\n",
      "- Time the performance of bubble sort on random uniform deviate vectors of sizes `range(100, 2000, 100)` using `time.time()` from the standard library\n",
      "- Use `scipy.optimize.curve_fit` to fit an appropriate function to the collection of (size, execution time) data points. Extrapolate how long it would take to sort a random vector of size 1,000,000. Now time how long it takes for the system sort to sort a random vector of size 1,000,000.\n",
      "- Plot the fits together with the data points uisng `matplotlib.pyplot` functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 4 (20 pts)**. One of the goals of the course it that you will be able to implement novel algorihtms from the literature. \n",
      "\n",
      "- Implement the mean-shift algorithm in 1D as described [here](http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/TUZEL1/MeanShift.pdf). \n",
      "    - Use the following function signature\n",
      "    ```python\n",
      "    def mean_shift(xs, x, kernel, max_iters=100, tol=1e-6):\n",
      "    ```\n",
      "    - xs is the data set, x is the starting location, and kernel is a kernel function\n",
      "    - tol is the difference in $||x||$ across iterations\n",
      "- Use the following kernels with bandwidth $h$ (a default value of 1.0 will work fine)\n",
      "    - Flat - return 1 if $||x|| < h$ and 0 otherwise\n",
      "    - Gaussian \n",
      "    $$\\frac{1}{\\sqrt{2 \\pi h}}e^{\\frac{-||x||^2}{h^2}}$$\n",
      "    - Note that $||x||$ is the norm of the data point being evaluated minus the current value of $x$\n",
      "- Use both kernels to find all 3 modes of the data set in `x1d.npy`\n",
      "- Modify the algorithm and/or kernels so that it now works in an arbitrary number of dimensions.\n",
      "- Use both kernels to find all 3 modes of the data set in `x2d.npy`\n",
      "- Plot the path of successive intermediate solutions of the mean-shift algorithm starting from `x0 = (-4, 10)` until it converges onto a mode in the 2D data for each kernel. Superimpose the path on top of a contour plot of the data density."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}