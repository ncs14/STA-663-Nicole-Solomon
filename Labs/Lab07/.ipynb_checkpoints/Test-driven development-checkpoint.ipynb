{
 "metadata": {
  "name": "",
  "signature": "sha256:491b7b009692b8bbfa99741433f632d741b262d637bd5c4a5582de3bee0dffb6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Basic test nomenclature\n",
      "----\n",
      "\n",
      "There are several levels of testing code. The most basic level is that of **unit tests**, which check that a single function does as expected. At a higher level are **integration tests**, which check that some combination of functions does as expected. **Regression tests** check if new changes to the code base break existing tests, and can be either unit or integration tests.\n",
      "\n",
      "< integration test: run a plot every now and then and make sure it gives something sensible.\n",
      "\n",
      "< regression test: everytime something is changed, run the code to see if something was broken.\n",
      "\n",
      "Unit tests are meant to be run automatically and are often used as regression tests - that is, run all unit tests after each significant code change. Because of this, unit tests should be completed in very short times (i.e. few seconds to complete **all** tests).\n",
      "\n",
      "Integration tests are sometimes not easy to put into an automated framework - if so, they shuold be designed to be easily run (e.g with a makefile) and generate test outputs that can be quickly scanned for errors.\n",
      "\n",
      "### Test-driven development\n",
      "\n",
      "The test-driven development philosophy recommends that tests be written before code, such that code is iteratively developed so as to pass an evolving series of tests. In this way, there is no need to write a suite of tests seprately, since the tests are already written in the process of code development. The development cycle goes like this:\n",
      "\n",
      "- add a test that will fail\n",
      "- write (minimal) code to fix failing test(s)\n",
      "- refactor code\n",
      "\n",
      "< forces you to think what the purpose of the code is; helps keep in mind a very specific goal for the code\n",
      "\n",
      "### Support for testing\n",
      "\n",
      "We will use the `py.test` (or `nose`) framework do develop our tests. Install with\n",
      "```\n",
      "pip install pytest\n",
      "```\n",
      "\n",
      "Test frameworks allow us to run tests in an isolated environment by using setup and teardown fixtures, and to do so auotmatically with simple commnand line arguments. We can also run tests in an IPython notebook (see http://zonca.github.io/2014/09/unit-tests-ipython-notebook.html) but this seems to be rather slow, so I will do them the old fashioned way."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A simple example of test-driven development\n",
      "\n",
      "We will develop a function to calculate Euclidean distance."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Tests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tests originally failed b/c duplicates of these tests existed in the following subdirectory -- delete this dir\n",
      "#rm -rf Reproducible/tests/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file distance.py\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "def euclidean_dist(u,v):\n",
      "    return np.sqrt(np.sum((u-v)**2))\n",
      "\n",
      "# def euclidean_dist(u, v):\n",
      "#     \"\"\"Returns Euclidean distance betwen numpy vectors u and v.\"\"\"\n",
      "#     w = u - v\n",
      "#     return np.sqrt(np.sum(w**2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting distance.py\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file test_distance.py\n",
      "\n",
      "import numpy as np\n",
      "from numpy.testing import assert_almost_equal\n",
      "from distance import euclidean_dist\n",
      "\n",
      "def test_non_negativity():\n",
      "    for i in range(10):\n",
      "        u = np.random.normal(3)\n",
      "        v = np.random.normal(3)\n",
      "        assert euclidean_dist(u, v) >= 0\n",
      "\n",
      "def test_coincidence_when_zero():\n",
      "    u = np.zeros(3)\n",
      "    v = np.zeros(3)\n",
      "    assert euclidean_dist(u, v) == 0\n",
      "\n",
      "def test_coincidence_when_not_zero():\n",
      "     for i in range(10):\n",
      "        u = np.random.random(3)\n",
      "        v = np.zeros(3)\n",
      "        assert euclidean_dist(u, v) != 0\n",
      "\n",
      "def test_symmetry():\n",
      "    for i in range(10):\n",
      "        u = np.random.random(3)\n",
      "        v = np.random.random(3)\n",
      "        assert euclidean_dist(u, v) == euclidean_dist(v, u)\n",
      "\n",
      "def test_triangle():\n",
      "    \n",
      "    u = np.random.random(3)\n",
      "    v = np.random.random(3)\n",
      "    w = np.random.random(3)\n",
      "    assert euclidean_dist(u, w) <= euclidean_dist(u, v) + euclidean_dist(v, w)\n",
      "\n",
      "def test_known1():\n",
      "    u = np.array([0])\n",
      "    v = np.array([3])\n",
      "    assert_almost_equal(euclidean_dist(u, v), 3)\n",
      "\n",
      "def test_known2():\n",
      "    u = np.array([0,0])\n",
      "    v = np.array([3, 4])\n",
      "    assert_almost_equal(euclidean_dist(u, v), 5)\n",
      "\n",
      "def test_known3():\n",
      "    u = np.array([0,0])\n",
      "    v = np.array([-3, -4])\n",
      "    assert_almost_equal(euclidean_dist(u, v), 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting test_distance.py\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! py.test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from numpy.testing import assert_almost_equal\n",
      "# import numpy as np\n",
      "\n",
      "# def test_1():\n",
      "#     u = np.array([3,4])\n",
      "#     v = np.array([0,0])\n",
      "#     assert_almost_equal(euclidean_dist(u,v),5) # assertion = claim that this is T and if F this will throw error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "want:\n",
      "functions.py\n",
      "test_functions.py\n",
      "\n",
      "directory:\n",
      "project\n",
      "  src\n",
      "    tests   --- test_proj1.py, test_proj1b.py\n",
      "    proj1.py\n",
      "    proj1b.py\n",
      "    \n",
      "python has 'unittests' in std libr, but is very verbose b/c it was pulled from java\n",
      "'doctests' - document string: '''>>>assert(3==result)''' ; drops > and other meaningless characters\n",
      "'nose'\n",
      "'py.test'\n",
      " - last two recognizes conventions for what is a test; unit and doc do not automatically know\n",
      "\n",
      "class TestX():\n",
      "\n",
      "Process:\n",
      "write test which will fail -- write requirements for fcn prior to writing the fcn\n",
      "write add'l code to make test pass\n",
      "write next test which will fail\n",
      "write add'l code to make test pass\n",
      "\n",
      "good convention: make test files mirror function files; i.e. if you want to know how a fcn works look at test_fcn\n",
      "\n",
      "Requirements:\n",
      "1. unit tests\n",
      "2. Functional test\n",
      "\n",
      "Separate test (functional) file:\n",
      "> sim data = gen data\n",
      "> fcn(sim data)\n",
      "> output; graph\n",
      "\n",
      "Unit tests:\n",
      " test known case\n",
      " test boundary conditions (at 0, or with scalar, etc.)\n",
      " check for 'off-by-one' errors (e.g. terminating loop with < vs <= --> how many iterations are you getting?)\n",
      " test for 'theorems' or properties (see test_symmetry above: dist(u,v) = dist(v,u))\n",
      " coverage = package; this goes through test & compares against lines of code & how much of code was covered by tests"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# re-copy makefile\n",
      "#cp /home/bitnami/STA663-2015/Labs/Lab07/Reproducible/Makefile /home/bitnami/STA-663-Nicole-Solomon/Labs/Lab07/Reproducible/\n",
      "\n",
      "Make file:\n",
      "target: dependency1 dependency2 (target expects dependencies to be present and this command will build up target file from these)\n",
      "    cmds\n",
      "    cmds\n",
      "    cmds\n",
      "    \n",
      "target1\n",
      "\n",
      "target2\n",
      "\n",
      ".phony == phony file (not target file)\n",
      "\n",
      "all == build all targets (e.g. all 15 reports)\n",
      "\n",
      "fcn call:\n",
      "make target (builds specific target)\n",
      "make all (builds all targets)\n",
      "make clean (removes autogenerated files; e.g. log file when compiling a latex doc)\n",
      "\n",
      "make (runs the very first target in dir)\n",
      "\n",
      "* need to have Makefile and should be able to run 'make all', 'make clean', ...?\n",
      "\n",
      "\n",
      "Example:\n",
      "\n",
      "report.pdf: blah blah blah\n",
      "    pdflatex report\n",
      "    pdflatex report\n",
      "    pdflatex report (run this 3x due to way latex works -- always have to recompile)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# so that the makefile properly compiles:\n",
      "#!pip install tabulate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Downloading/unpacking tabulate\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Downloading tabulate-0.7.4.tar.gz\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Running setup.py (path:/tmp/pip_build_bitnami/tabulate/setup.py) egg_info for package tabulate\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    \r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Installing collected packages: tabulate\r\n",
        "  Running setup.py install for tabulate\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    \r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    Installing tabulate script to /home/bitnami/anaconda/bin\r\n",
        "Successfully installed tabulate\r\n",
        "Cleaning up...\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Notes on numeric functions\n",
      "\n",
      "See http://docs.scipy.org/doc/numpy/reference/routines.testing.html for useful functions to deal with testing functions that return floating point scalars or vectors."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### What about stochastic functions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several options:\n",
      "\n",
      "- Use a fixed seed and test for known outputs - this converts a stochastic funciton into a determinsitic one\n",
      "- Use statistical criteria that are highly unlikley to be breached if the funciton is wokring correctly (e.g. acceptable bounds for point estimtes)\n",
      "- run as integration test and genearte output that can be easily checked - e.g. easily interptetable plots (these are only run occasionally)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}