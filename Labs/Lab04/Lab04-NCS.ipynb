{
 "metadata": {
  "name": "",
  "signature": "sha256:6dbf6e038ff740661791934d1847f5ac73009ae4957a739e6e9ac9fa58b4eb5f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 307
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la\n",
      "import scipy.stats as st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 308
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 309
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format},linewidth=90)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 310
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Latent Semantic Analysis (LSA) is a method for reducing the dimensionality of documents treated as a bag of words. It is used for document classification, clustering and retrieval. For example, LSA can be used to search for prior art given a new patent application. In this homework, we will implement a small library for simple latent semantic analysis as a practical example of the application of SVD. The ideas are very similar to PCA.\n",
      "\n",
      "We will implement a toy example of LSA to get familiar with the ideas. If you want to use LSA or similar methods for statistical language analyis, the most efficient Python library is probably [gensim](https://radimrehurek.com/gensim/) - this also provides an online algorithm - i.e. the training information can be continuously updated. Other useful functions for processing natural language can be found in the [Natural Language Toolkit](http://www.nltk.org/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note**: The SVD from scipy.linalg performs a full decomposition, which is inefficient since we only need to decompose until we get the first k singular values. If the SVD from `scipy.linalg` is too slow, please use the `sparsesvd` function from the [sparsesvd](https://pypi.python.org/pypi/sparsesvd/) package to perform SVD instead.  You can install in the usual way with \n",
      "```\n",
      "!pip install sparsesvd\n",
      "```\n",
      "\n",
      "Then import the following\n",
      "```python\n",
      "from sparsesvd import sparsesvd \n",
      "from scipy.sparse import csc_matrix \n",
      "```\n",
      "\n",
      "and use as follows\n",
      "```python\n",
      "sparsesvd(csc_matrix(M), k=10)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 1 (10 points)**.  Calculating pairwise distance matrices.\n",
      "\n",
      "Suppose we want to construct a distance matrix between the rows of a matrix. For example, given the matrix \n",
      "\n",
      "```python\n",
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "```\n",
      "\n",
      "the distance matrix using Euclidean distance as the measure would be\n",
      "```python\n",
      "[[ 0.000  1.414  2.828]\n",
      " [ 1.414  0.000  1.414]\n",
      " [ 2.828  1.414  0.000]] \n",
      "```\n",
      "if $M$ was a collection of column vectors.\n",
      "\n",
      "Write a function to calculate the pairwise-distance matrix given the matrix $M$ and some arbitrary distance function. Your functions should have the following signature:\n",
      "```\n",
      "def func_name(M, distance_func):\n",
      "    pass\n",
      "```\n",
      "\n",
      "0. Write a distance function for the Euclidean, squared Euclidean and cosine measures.\n",
      "1. Write the function using looping for M as a collection of row vectors.\n",
      "2. Write the function using looping for M as a collection of column vectors.\n",
      "3. Write the function using broadcasting for M as a collection of row vectors.\n",
      "4. Write the function using broadcasting for M as a collection of column vectors. \n",
      "\n",
      "For 3 and 4, try to avoid using transposition (but if you get stuck, there will be no penalty for using transposition). Check that all four functions give the same result when applied to the given matrix $M$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "print M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[1 2 3]\n",
        " [4 5 6]]\n"
       ]
      }
     ],
     "prompt_number": 311
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def euc_dist(a,b):\n",
      "    \"\"\" Euclidean distance btwn 2x1 vectors a,b \"\"\"\n",
      "    return np.sqrt(np.sum((a-b)**2,-1))\n",
      "\n",
      "def sq_euc_dist(a,b):\n",
      "    \"\"\" Squared Euclidean distance btwn 2x1 vectors a,b \"\"\"\n",
      "    return euc_dist(a,b)**2\n",
      "\n",
      "def cos_dist(a,b):\n",
      "    \"\"\" Cosine distance btwn 2x1 vectors a,b \"\"\"\n",
      "    return np.sum(a*b,-1)/np.sqrt(np.sum(a*a,-1)*np.sum(b*b,-1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 312
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loop_row(A,distfcn):\n",
      "    \"\"\" Function to compute distance matrix w looping \"\"\"\n",
      "    \"\"\" apply distance fcn 'distfcn' to matrix M = collection of row vectors \"\"\"\n",
      "    # compute distfcn for full length of row vectors\n",
      "    s = A.shape[0]\n",
      "    return np.array([distfcn(A[j,:],A[i,:]) for i in range(s) for j in range(s)]).reshape(s,s)\n",
      "\n",
      "\n",
      "def loop_col(A,distfcn):\n",
      "    \"\"\" Function to compute distance matrix w looping \"\"\"\n",
      "    \"\"\" apply distance fcn 'distfcn' to matrix M = collection of col vectors \"\"\"\n",
      "    # compute distfcn for full number of col vectors\n",
      "    s = A.shape[1]\n",
      "    return np.array([distfcn(A[:,j],A[:,i]) for i in range(s) for j in range(s)]).reshape(s,s)\n",
      "\n",
      "\n",
      "def broad_row(A,distfcn):\n",
      "    \"\"\" Function to compute distance matrix w broadcasting \"\"\"\n",
      "    \"\"\" apply distance fcn 'distfcn' to matrix M = collection of row vectors \"\"\"\n",
      "    return distfcn(A[None,:],A[:,None])\n",
      "    \n",
      "def broad_col(A,distfcn):\n",
      "    \"\"\" Function to compute distance matrix w broadcasting \"\"\"\n",
      "    \"\"\" apply distance fcn 'distfcn' to matrix M = collection of col vectors \"\"\"\n",
      "    # transpose col vector collection for easier computations\n",
      "    A2 = A.T\n",
      "    return distfcn(A2[None,:],A2[:,None])\n",
      "\n",
      "\n",
      "#### Test functions\n",
      "print \"Looping on M as collection of row vectors: \\n\"\n",
      "print \"Euclidean distance matrix: \\n\", loop_row(M,euc_dist)\n",
      "print \"Squared Euclidean distance matrix: \\n\", loop_row(M,sq_euc_dist)\n",
      "print \"Cosine distance matrix: \\n\", loop_row(M,cos_dist)\n",
      "\n",
      "print \"\\nBroadcasting on M as collection of row vectors: \\n\"\n",
      "print \"Euclidean distance matrix: \\n\", broad_row(M,euc_dist)\n",
      "print \"Squared Euclidean distance matrix: \\n\", broad_row(M,sq_euc_dist)\n",
      "print \"Cosine distance matrix: \\n\", broad_row(M,cos_dist)\n",
      "\n",
      "print \"\\nLooping on M as collection of col vectors: \\n\"\n",
      "print \"Euclidean distance matrix: \\n\", loop_col(M,euc_dist)\n",
      "print \"Squared Euclidean distance matrix: \\n\", loop_col(M,sq_euc_dist)\n",
      "print \"Cosine distance matrix: \\n\", loop_col(M,cos_dist)\n",
      "\n",
      "print \"\\nBroadcasting on M as collection of col vectors: \\n\"\n",
      "print \"Euclidean distance matrix: \\n\", broad_col(M,euc_dist)\n",
      "print \"Squared Euclidean distance matrix: \\n\", broad_col(M,sq_euc_dist)\n",
      "print \"Cosine distance matrix: \\n\", broad_col(M,cos_dist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Looping on M as collection of row vectors: \n",
        "\n",
        "Euclidean distance matrix: \n",
        "[[ 0.000  5.196]\n",
        " [ 5.196  0.000]]\n",
        "Squared Euclidean distance matrix: \n",
        "[[ 0.000  27.000]\n",
        " [ 27.000  0.000]]\n",
        "Cosine distance matrix: \n",
        "[[ 1.000  0.975]\n",
        " [ 0.975  1.000]]\n",
        "\n",
        "Broadcasting on M as collection of row vectors: \n",
        "\n",
        "Euclidean distance matrix: \n",
        "[[ 0.000  5.196]\n",
        " [ 5.196  0.000]]\n",
        "Squared Euclidean distance matrix: \n",
        "[[ 0.000  27.000]\n",
        " [ 27.000  0.000]]\n",
        "Cosine distance matrix: \n",
        "[[ 1.000  0.975]\n",
        " [ 0.975  1.000]]\n",
        "\n",
        "Looping on M as collection of col vectors: \n",
        "\n",
        "Euclidean distance matrix: \n",
        "[[ 0.000  1.414  2.828]\n",
        " [ 1.414  0.000  1.414]\n",
        " [ 2.828  1.414  0.000]]\n",
        "Squared Euclidean distance matrix: \n",
        "[[ 0.000  2.000  8.000]\n",
        " [ 2.000  0.000  2.000]\n",
        " [ 8.000  2.000  0.000]]\n",
        "Cosine distance matrix: \n",
        "[[ 1.000  0.991  0.976]\n",
        " [ 0.991  1.000  0.997]\n",
        " [ 0.976  0.997  1.000]]\n",
        "\n",
        "Broadcasting on M as collection of col vectors: \n",
        "\n",
        "Euclidean distance matrix: \n",
        "[[ 0.000  1.414  2.828]\n",
        " [ 1.414  0.000  1.414]\n",
        " [ 2.828  1.414  0.000]]\n",
        "Squared Euclidean distance matrix: \n",
        "[[ 0.000  2.000  8.000]\n",
        " [ 2.000  0.000  2.000]\n",
        " [ 8.000  2.000  0.000]]\n",
        "Cosine distance matrix: \n",
        "[[ 1.000  0.991  0.976]\n",
        " [ 0.991  1.000  0.997]\n",
        " [ 0.976  0.997  1.000]]\n"
       ]
      }
     ],
     "prompt_number": 313
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 2 (10 points)**. Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf). Each function should take a single argument `docs`, which is a dictionary of (key=identifier, value=document text) pairs, and return an appropriately sized array. Convert '-' to ' ' (space), remove punctuation, convert text to lowercase and split on whitespace to generate a collection of terms from the document text.\n",
      "\n",
      "- tf = the number of occurrences of term $i$ in document $j$\n",
      "- idf = $\\log \\frac{n}{1 + \\text{df}_i}$ where $n$ is the total number of documents and $\\text{df}_i$ is the number of documents in which term $i$ occurs.\n",
      "\n",
      "Print the table of tf-idf values for the following document collection\n",
      "\n",
      "```\n",
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "```\n",
      "\n",
      "Note: You can use either a numpy array or pandas dataframe to store the matrix. However, we suggest using a Pandas dataframe since that will allow you to keep track of the row (term) and column (document) names in a single object. Of course, you could also maintain a numpy matrix, a list of terms, and a list of documents separately if you prefer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs0 = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "\n",
      "\n",
      "#### In order to delete punctuation, import it from string\n",
      "from string import punctuation\n",
      "\n",
      "\n",
      "#### In order to tally words in the text, import Counter\n",
      "from collections import Counter\n",
      "\n",
      "\n",
      "def tf(docs):\n",
      "    \"\"\"Returns the number of times each term occurs in a document.\n",
      "    We preprocess the document to strip punctuation and convert to lowercase.\n",
      "    Terms are found by splitting on whitespace.\"\"\"\n",
      "    countlist = []\n",
      "    for j in range(len(docs)):\n",
      "        # Sort doc keys to output term freq in same order as docs in dictionary\n",
      "        keys = sorted(docs.keys())\n",
      "        # Clean up text in document j\n",
      "        docj_terms = docs[keys[j]].replace('-',' ').translate(None, punctuation).lower().split()\n",
      "        # Count frequency of terms \n",
      "        countlist.append(dict(Counter(docj_terms)))\n",
      "    return countlist\n",
      "        \n",
      "\n",
      "def tfs(docs):\n",
      "    \"\"\"Create a term frequency dataframe from a dictionary of documents.\"\"\"\n",
      "    # create dataframe from dictionary counts calculated with tf(docs)\n",
      "    countdf = pd.DataFrame(tf(docs)).T\n",
      "    # replace NaN's with 0's \n",
      "    countdf[np.isnan(countdf)] = 0\n",
      "    # rename columns\n",
      "    countdf.columns = sorted(docs.keys())\n",
      "    return countdf\n",
      "    \n",
      "\n",
      "def idf(docs):\n",
      "    \"\"\"Find inverse document frequency series from a dictionary of documents.\"\"\"\n",
      "    n = len(docs)\n",
      "    countdf = tfs(docs)\n",
      "    # keep track of dfi\n",
      "    idfcount = []\n",
      "    for i in range(np.shape(countdf)[0]):\n",
      "        # pull the term row from tfs(docs)\n",
      "        dfrow = countdf.iloc[i,:]\n",
      "        # tally how many non-zero cells term has\n",
      "        dfi = (len(dfrow[dfrow!=0]))\n",
      "        # compute idf\n",
      "        idfcount.append(np.log(n/(1.+dfi)))\n",
      "    idf_df = pd.DataFrame(idfcount,list(countdf.index))\n",
      "    idf_df.columns = ['idf']\n",
      "    return idf_df\n",
      "        \n",
      "\n",
      "def tf_idf(docs):\n",
      "    \"\"\"Return the product of the term-frequency and inverse document frequency.\"\"\"\n",
      "    # compute term frequencies\n",
      "    tfdocs = tfs(docs)\n",
      "    # compute idfs\n",
      "    idfdocs = idf(docs)\n",
      "    # retain unique terms\n",
      "    tf_keys = list(tfdocs.index)\n",
      "    # multiply doc j's tfs by respective idf\n",
      "    for i in range(len(tf_keys)):\n",
      "        tfdocs.iloc[i,:] = np.array(tfdocs.iloc[i,:][:,np.newaxis] * idfdocs.iloc[i][np.newaxis,:]).reshape(tfdocs.shape[1])\n",
      "    return tfdocs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 314
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf(docs0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 315,
       "text": [
        "[{'brown': 1, 'fox': 1, 'quick': 1, 'the': 1},\n",
        " {'brown': 1, 'fox': 1, 'jumps': 4, 'over': 1, 'the': 1},\n",
        " {'dog': 1, 'elephant': 1, 'lazy': 1, 'the': 3},\n",
        " {'dog': 1, 'elephant': 1, 'lion': 1, 'peacock': 1, 'the': 5, 'tiger': 1}]"
       ]
      }
     ],
     "prompt_number": 315
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfs(docs0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>s1</th>\n",
        "      <th>s2</th>\n",
        "      <th>s3</th>\n",
        "      <th>s4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>brown</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>dog</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>elephant</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>fox</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>jumps</th>\n",
        "      <td> 0</td>\n",
        "      <td> 4</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lazy</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lion</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>over</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>peacock</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quick</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td> 5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tiger</th>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 316,
       "text": [
        "          s1  s2  s3  s4\n",
        "brown      1   1   0   0\n",
        "dog        0   0   1   1\n",
        "elephant   0   0   1   1\n",
        "fox        1   1   0   0\n",
        "jumps      0   4   0   0\n",
        "lazy       0   0   1   0\n",
        "lion       0   0   0   1\n",
        "over       0   1   0   0\n",
        "peacock    0   0   0   1\n",
        "quick      1   0   0   0\n",
        "the        1   1   3   5\n",
        "tiger      0   0   0   1"
       ]
      }
     ],
     "prompt_number": 316
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "idf(docs0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>idf</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>brown</th>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>dog</th>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>elephant</th>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>fox</th>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>jumps</th>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lazy</th>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lion</th>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>over</th>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>peacock</th>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quick</th>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>-0.223144</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tiger</th>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 317,
       "text": [
        "               idf\n",
        "brown     0.287682\n",
        "dog       0.287682\n",
        "elephant  0.287682\n",
        "fox       0.287682\n",
        "jumps     0.693147\n",
        "lazy      0.693147\n",
        "lion      0.693147\n",
        "over      0.693147\n",
        "peacock   0.693147\n",
        "quick     0.693147\n",
        "the      -0.223144\n",
        "tiger     0.693147"
       ]
      }
     ],
     "prompt_number": 317
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tf_idf(docs0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>s1</th>\n",
        "      <th>s2</th>\n",
        "      <th>s3</th>\n",
        "      <th>s4</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>brown</th>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>dog</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>elephant</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>fox</th>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.287682</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>jumps</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 2.772589</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lazy</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>lion</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>over</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>peacock</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>quick</th>\n",
        "      <td> 0.693147</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>the</th>\n",
        "      <td>-0.223144</td>\n",
        "      <td>-0.223144</td>\n",
        "      <td>-0.669431</td>\n",
        "      <td>-1.115718</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>tiger</th>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.693147</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 318,
       "text": [
        "                s1        s2        s3        s4\n",
        "brown     0.287682  0.287682  0.000000  0.000000\n",
        "dog       0.000000  0.000000  0.287682  0.287682\n",
        "elephant  0.000000  0.000000  0.287682  0.287682\n",
        "fox       0.287682  0.287682  0.000000  0.000000\n",
        "jumps     0.000000  2.772589  0.000000  0.000000\n",
        "lazy      0.000000  0.000000  0.693147  0.000000\n",
        "lion      0.000000  0.000000  0.000000  0.693147\n",
        "over      0.000000  0.693147  0.000000  0.000000\n",
        "peacock   0.000000  0.000000  0.000000  0.693147\n",
        "quick     0.693147  0.000000  0.000000  0.000000\n",
        "the      -0.223144 -0.223144 -0.669431 -1.115718\n",
        "tiger     0.000000  0.000000  0.000000  0.693147"
       ]
      }
     ],
     "prompt_number": 318
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 3 (10 points)**. \n",
      "\n",
      "1. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linagl.svd` function to perform the decomposition. This is the least squares approximation to the matrix $M$ in $k$ dimensions.\n",
      "\n",
      "2. Apply the function you just wrote to the following term-frequency matrix for a set of $9$ documents using $k=2$ and print the reconstructed matrix $M'$.\n",
      "```\n",
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "```\n",
      "\n",
      "3. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do the calculations). Consider the first 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlation for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!pip install sparsesvd\n",
      "\n",
      "from sparsesvd import sparsesvd \n",
      "from scipy.sparse import csc_matrix\n",
      "\n",
      "#sparsesvd(csc_matrix(M), k=9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 319
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "    [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "    [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "    [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "\n",
      "\n",
      "def svd_k(A,k):\n",
      "    \"\"\" SVD Decomposition for Reduction to k Dimensions \"\"\"\n",
      "    # conduct SVD\n",
      "    U, S, V = la.svd(A, full_matrices=False)\n",
      "    # set any singular values > k to 0\n",
      "    S[k:] = 0\n",
      "    # Reconstruct the approximation of M in k dimensions\n",
      "    A2 = np.dot(U,np.dot(np.diag(S),V))\n",
      "    return A2, U[:,:k], np.diag(S[:k]), V[:k,:]\n",
      "\n",
      "#### Confirm the function returns M when k = num col of M\n",
      "np.allclose(M,svd_k(M,M.shape[1])[0])\n",
      "\n",
      "\n",
      "#### Run function on tf matrix, k=2\n",
      "M2 = svd_k(M,2)[0]\n",
      "print \"2-dimension reduced M' matrix: \\n\", M2\n",
      "\n",
      "\n",
      "#### Pairwise corr matrices\n",
      "corrM = st.spearmanr(M)[0]\n",
      "corrM2 = st.spearmanr(M2)[0]\n",
      "#print \"\\nPairwise corr matrix of M:\\n\", corrM\n",
      "#print \"\\nPairwise corr matrix of M':\\n\", corrM2\n",
      "\n",
      "  ### Within G1 average corr\n",
      "G1corr = corrM[:5,:5]\n",
      "print \"\\nAvg within G1 corr of M:\", round(G1corr[G1corr<1.0].mean(),3)\n",
      "  ### Within G2 average corr\n",
      "G2corr = corrM[5:,5:]\n",
      "print \"\\nAvg within G2 corr of M:\", round(G2corr[G2corr<1.0].mean(),3)\n",
      "  ### Cross G1-G2 average corr\n",
      "G1G2corr = corrM[:5,5:]\n",
      "print \"\\nAvg cross G1-G2 corr of M:\", round(G1G2corr[G1G2corr<1.0].mean(),3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2-dimension reduced M' matrix: \n",
        "[[ 0.162  0.400  0.379  0.468  0.176 -0.053 -0.115 -0.159 -0.092]\n",
        " [ 0.141  0.370  0.329  0.400  0.165 -0.033 -0.071 -0.097 -0.043]\n",
        " [ 0.152  0.505  0.358  0.410  0.236  0.024  0.060  0.087  0.124]\n",
        " [ 0.258  0.841  0.606  0.697  0.392  0.033  0.083  0.122  0.187]\n",
        " [ 0.449  1.234  1.051  1.266  0.556 -0.074 -0.155 -0.210 -0.049]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.218  0.550  0.511  0.628  0.243 -0.065 -0.143 -0.197 -0.108]\n",
        " [ 0.097  0.532  0.230  0.212  0.267  0.137  0.315  0.444  0.425]\n",
        " [-0.061  0.232 -0.139 -0.266  0.145  0.240  0.546  0.767  0.664]\n",
        " [-0.065  0.335 -0.146 -0.301  0.203  0.306  0.695  0.977  0.849]\n",
        " [-0.043  0.254 -0.097 -0.208  0.152  0.221  0.503  0.707  0.616]]\n",
        "\n",
        "Avg within G1 corr of M: 0.011\n",
        "\n",
        "Avg within G2 corr of M: 0.435\n",
        "\n",
        "Avg cross G1-G2 corr of M: -0.308\n"
       ]
      }
     ],
     "prompt_number": 320
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 4 (20 points)**. Clustering with LSA\n",
      "\n",
      "1. Begin by loading a pubmed database of selected article titles using 'cPickle'. With the following:\n",
      "```import cPickle\n",
      "docs = cPickle.load(open('pubmed.pic'))```\n",
      "\n",
      "    Create a tf-idf matrix for every term that appears at least once in any of the documents. What is the shape of the tf-idf matrix? \n",
      "\n",
      "2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$ (often written as $T \\Sigma D^T$ in this context with $T$ representing the terms and $D$ representing the documents). If we set all but the top $k$ singular values to 0, the reconstructed matrix is essentially $U_k \\Sigma_k V_k^T$, where $U_k$ is $m \\times k$, $\\Sigma_k$ is $k \\times k$ and $V_k^T$ is $k \\times n$. Terms in this reduced space are represented by $U_k \\Sigma_k$ and documents by $\\Sigma_k V^T_k$. Reconstruct the matrix using the first $k=10$ singular values.\n",
      "\n",
      "3. Use agglomerative hierachical clustering with complete linkage to plot a dendrogram and comment on the likely number of  document clusters with $k = 100$. Use the dendrogram function from [SciPy ](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html).\n",
      "\n",
      "4. Determine how similar each of the original documents is to the new document `mystery.txt`. Since $A = U \\Sigma V^T$, we also have $V = A^T U S^{-1}$ using orthogonality and the rule for transposing matrix products. This suggests that in order to map the new document to the same concept space, first find the tf-idf vector $v$ for the new document - this must contain all (and only) the terms present in the existing tf-idf matrix. Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Find the 10 documents most similar to the new document and the 10 most dissimilar. \n",
      "\n",
      "5. Many documents often have some boilerplate material such as organization information, Copyright, etc. at the front or back of the document. Does it matter that the front and back matter of each document is essentially identical for either LSA-based clustering (part 3) or information retrieval (part 4)? Why or why not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_pub = cPickle.load(open('pubmed.pic'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 321
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf_pub = tf_idf(d_pub)\n",
      "print \"Shape of pubmed tf-idf matrix:\", tidf_pub.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Shape of pubmed tf-idf matrix: (6488, 178)\n"
       ]
      }
     ],
     "prompt_number": 322
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svd_pub = svd_k(tfidf_pub,10)[0]\n",
      "print \"Reconstructed tf-idf matrix to k=10 dimensions:\\n\", svd_pub"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reconstructed tf-idf matrix to k=10 dimensions:\n",
        "[[ 0.044 -0.051  0.177 ...,  0.023  0.127 -0.210]\n",
        " [ 0.003  0.043  0.008 ...,  0.035  0.029  0.092]\n",
        " [ 0.002 -0.076  0.066 ..., -0.041 -0.009 -0.180]\n",
        " ..., \n",
        " [ 0.008  0.009  0.016 ...,  0.006  0.026  0.012]\n",
        " [ 0.031  0.122  0.070 ...,  0.093  0.128  0.198]\n",
        " [ 0.008  0.016  0.017 ...,  0.011  0.031  0.026]]\n"
       ]
      }
     ],
     "prompt_number": 323
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.cluster.hierarchy as sc\n",
      "\n",
      "svd_pub100 = svd_k(tfidf_pub,100)[0]\n",
      "\n",
      "#### Cosine distance matrix of the reduced tf-idf matrix\n",
      "dist_pub = broad_col(svd_pub100,cos_dist)\n",
      "\n",
      "#### Complete linkage object of the distance matrix\n",
      "link_pub = sc.linkage(dist_pub,\"complete\")\n",
      "\n",
      "#### Dendrogram of the linkage object\n",
      "plt.title(\"Dendrogram of reduced (k=100) pubmed articles\")\n",
      "dendro_pub = sc.dendrogram(link_pub, orientation='right')\n",
      "\n",
      "\n",
      "\"\"\" Based on the dendrogram, at k=100 there may be 13 clusters total. \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 324,
       "text": [
        "' Based on the dendrogram, at k=100 there may be 13 clusters total. '"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fe4950611d0>"
       ]
      }
     ],
     "prompt_number": 324
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Read in mystery.txt\n",
      "mystery = open('mystery.txt','r')\n",
      "mys = {'mystery': mystery.read()}\n",
      "\n",
      "\n",
      "#### Compute tf-idf matrix on mystery text\n",
      "tfidf_mys = tf_idf(mys)\n",
      "    # 231 terms\n",
      "\n",
      "\n",
      "#### Intersect the terms of pubmed and mystery\n",
      "terms_pub = pd.Series(list(tfidf_pub.index))\n",
      "terms_mys = pd.Series(list(tfidf_mys.index))\n",
      "common_terms = pd.Series(np.intersect1d(terms_pub,terms_mys))\n",
      "    # 191 terms in common\n",
      "\n",
      "\n",
      "#### Retain the tf-idf matrix of only the intersecting terms\n",
      "v = tfidf_mys.loc[list(common_terms),:]\n",
      "td_pub_v = tfidf_pub.loc[list(common_terms),:] # --> U, S for calculation of query vector\n",
      "    # 191 terms x 178 documents\n",
      "\n",
      "\n",
      "#### Compute query vector q = v^T U S^(-1)\n",
      "  # select a reduced dimension value kv\n",
      "kv=40\n",
      "  # perform SVD on the intersected tf-idf matrix of pubmed\n",
      "svd_pub_v = svd_k(td_pub_v,kv)\n",
      "U, S, V = svd_pub_v[1], svd_pub_v[2], svd_pub_v[3]\n",
      "  # calculate the query vector\n",
      "q = np.dot(v.T,np.dot(U,la.inv(S)))\n",
      "print (\"Query vector under k=%s:\\n\" %kv)\n",
      "print q, \"\\n\"\n",
      "  # query dimension: 1xkv\n",
      "\n",
      "\n",
      "#### Determine 10 documents most similar / dissimilar\n",
      "  # combine the query vector^T and V --> kv x (178+1) matrix\n",
      "mys_pub = np.insert(V,0,q,axis=1)\n",
      "    # kv terms/dim x 179 documents\n",
      "\n",
      "\n",
      "#### Compute correlation matrix btwn mystery query vector and pubmed docs\n",
      "corr_q_pub = st.spearmanr(mys_pub)[0]\n",
      "    # 179 x 179 document correlations\n",
      "corrs = corr_q_pub[1:,0] # retain the correlations btwn query & 178 pubmed docs\n",
      "most_similar = np.argsort(corrs)[::-1][:10] # top 10 (lgst corrs)\n",
      "most_dissimilar = np.argsort(corrs)[::-1][(len(corrs)-10):] # last 10 (smst [most neg] corrs)\n",
      "\n",
      "\n",
      "#### Collect document titles for identification of most (dis)similar docs\n",
      "titles0 = list(tfidf_pub.columns)\n",
      "  # truncate titles after 50 characters\n",
      "titles = [(x[:50] + '...') if len(x) > 50 else x for x in titles0]\n",
      "\n",
      "\n",
      "print \"Most similar documents:\\n\", most_similar\n",
      "print \"\\nCorrelations of most similar: \\n\", corrs[most_similar]\n",
      "print \"\\nTitle previews of most similar documents:\\n  \", \"\\n   \".join([titles[y] for y in most_similar])\n",
      "\n",
      "print \"\\nMost dissimilar documents:\\n\", most_dissimilar\n",
      "print \"\\nCorrelations of most dissimilar:\\n\", corrs[most_dissimilar]\n",
      "print \"\\nTitle previews of most dissimilar documents:\\n  \", \"\\n   \".join([titles[y] for y in most_dissimilar])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query vector under k=40:\n",
        "\n",
        "[[ 0.259 -0.024 -0.042 -0.089 -0.049  0.043 -0.025  0.028  0.007 -0.048  0.028 -0.047\n",
        "  -0.034 -0.055  0.044 -0.036 -0.049  0.075 -0.055  0.030 -0.164 -0.127 -0.164  0.058\n",
        "   0.004  0.020  0.038 -0.033 -0.053 -0.048  0.005 -0.194 -0.042 -0.076  0.015  0.064\n",
        "  -0.130 -0.090  0.148  0.024]] \n",
        "\n",
        "Most similar documents:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[141 118 111 132 140  32 135 154  38 143]\n",
        "\n",
        "Correlations of most similar: \n",
        "[ 0.280  0.207  0.207  0.196  0.195  0.179  0.177  0.152  0.149  0.148]\n",
        "\n",
        "Title previews of most similar documents:\n",
        "   Safety and effect on reported symptoms of depigmen...\n",
        "   Omalizumab for severe allergic asthma in clinical ...\n",
        "   Mycobacterium tuberculosis EspB protein suppresses...\n",
        "   Real-World Evaluation of the Effects of Counseling...\n",
        "   SMS photograph-based external quality assessment o...\n",
        "   Cellular immune surveillance of central nervous sy...\n",
        "   Removal of peanut allergen Ara h 1 from common hos...\n",
        "   The apicomplexan parasite Babesia divergens intern...\n",
        "   Clinical Efficacy and Immunological Effects of Oma...\n",
        "   Serum inflammatory factors and circulating immunos...\n",
        "\n",
        "Most dissimilar documents:\n",
        "[ 31 161 108  57  40  71  93 116  96 114]\n",
        "\n",
        "Correlations of most dissimilar:\n",
        "[-0.361 -0.361 -0.389 -0.396 -0.446 -0.446 -0.456 -0.492 -0.495 -0.505]\n",
        "\n",
        "Title previews of most dissimilar documents:\n",
        "   CFTR Gene Mutations and Asthma in Indian Children:...\n",
        "   Time-to-infection by Plasmodium falciparum is larg...\n",
        "   Molecular detection of Plasmodium in free-ranging ...\n",
        "   Effects of the Flavanone combination Hesperetin-Na...\n",
        "   Comparison of mercury blood pressure readings with...\n",
        "   Gas, dust and fume exposure is associated with mit...\n",
        "   Induction and mechanism of HeLa cell apoptosis by ...\n",
        "   Ni(II)NTA AuNPs as a low-resource malarial diagnos...\n",
        "   Involvement of ROS-p38-H2AX axis in novel curcumin...\n",
        "   Nerve Growth Factor Potentiates Nicotinic Synaptic...\n"
       ]
      }
     ],
     "prompt_number": 325
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "st = \"\"\"\n",
      "Broilerplate material matters with documents that have little unique text - that are primarily comprised of\n",
      "broilerplate material. This is true when the broilerplate material is not of interest and when it is \n",
      "desirable to group documents based on unique text. In this case the broilerplate should be removed in order\n",
      "to not mistakenly group documents with relatively small amounts of unique but very different text in the \n",
      "same cluster. This is true with both methods.\n",
      "\n",
      "For documents with large amounts of unique text, broilerplates will have little effect on these two\n",
      "techniques since terms common across all documents have lower idf's and so are downweighted in the tf-idf\n",
      "matrices. Additionally, the information retrieval method may be more robust since it performs dimension \n",
      "reduction and thereby keeps information on the unique differences between documents and drops similar info; \n",
      "i.e. downweights the broilerplates.\n",
      "\"\"\"\n",
      "\n",
      "print st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Broilerplate material matters with documents that have little unique text - that are primarily comprised of\n",
        "broilerplate material. This is true when the broilerplate material is not of interest and when it is \n",
        "desirable to group documents based on unique text. In this case the broilerplate should be removed in order\n",
        "to not mistakenly group documents with relatively small amounts of unique but very different text in the \n",
        "same cluster. This is true with both methods.\n",
        "\n",
        "For documents with large amounts of unique text, broilerplates will have little effect on these two\n",
        "techniques since terms common across all documents have lower idf's and so are downweighted in the tf-idf\n",
        "matrices. Additionally, the information retrieval method may be more robust since it performs dimension \n",
        "reduction and thereby keeps information on the unique differences between documents and drops similar info; \n",
        "i.e. downweights the broilerplates.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 326
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notes on the Pubmed articles\n",
      "----\n",
      "\n",
      "These were downloaded with the following script.\n",
      "\n",
      "```python\n",
      "from Bio import Entrez, Medline\n",
      "Entrez.email = \"YOUR EMAIL HERE\"\n",
      "import cPickle\n",
      "\n",
      "try:\n",
      "    docs = cPickle.load(open('pubmed.pic'))\n",
      "except Exception, e:\n",
      "    print e\n",
      "\n",
      "    docs = {}\n",
      "    for term in ['plasmodium', 'diabetes', 'asthma', 'cytometry']:\n",
      "        handle = Entrez.esearch(db=\"pubmed\", term=term, retmax=50)\n",
      "        result = Entrez.read(handle)\n",
      "        handle.close()\n",
      "        idlist = result[\"IdList\"]\n",
      "        handle2 = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
      "        result2 = Medline.parse(handle2)\n",
      "        for record in result2:\n",
      "            title = record.get(\"TI\", None)\n",
      "            abstract = record.get(\"AB\", None)\n",
      "            if title is None or abstract is None:\n",
      "                continue\n",
      "            docs[title] = '\\n'.join([title, abstract])\n",
      "            print title\n",
      "        handle2.close()\n",
      "    cPickle.dump(docs, open('pubmed.pic', 'w'))\n",
      "docs.values()\n",
      "```"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}